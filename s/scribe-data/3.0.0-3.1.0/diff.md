# Comparing `tmp/scribe_data-3.0.0-py3-none-any.whl.zip` & `tmp/scribe_data-3.1.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,8 +1,8 @@
-Zip file size: 107429 bytes, number of entries: 73
+Zip file size: 107908 bytes, number of entries: 73
 -rw-r--r--  2.0 unx        0 b- defN 22-Apr-06 08:21 scribe_data/__init__.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Apr-05 19:22 scribe_data/extract_transform/__init__.py
 -rw-r--r--  2.0 unx     8252 b- defN 23-Apr-17 15:55 scribe_data/extract_transform/emoji_utils.py
 -rw-r--r--  2.0 unx    13956 b- defN 23-Apr-10 20:09 scribe_data/extract_transform/extract_wiki.py
 -rw-r--r--  2.0 unx     9447 b- defN 23-Apr-17 16:01 scribe_data/extract_transform/process_unicode.py
 -rw-r--r--  2.0 unx    12277 b- defN 23-Apr-10 21:27 scribe_data/extract_transform/process_wiki.py
 -rw-r--r--  2.0 unx    14322 b- defN 23-Apr-17 16:28 scribe_data/extract_transform/update_data.py
@@ -13,15 +13,15 @@
 -rw-r--r--  2.0 unx     1266 b- defN 23-Apr-10 20:12 scribe_data/extract_transform/French/translations/format_translations.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Apr-05 19:43 scribe_data/extract_transform/French/verbs/__init__.py
 -rw-r--r--  2.0 unx     2271 b- defN 23-Apr-16 22:47 scribe_data/extract_transform/French/verbs/format_verbs.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Apr-05 19:44 scribe_data/extract_transform/German/__init__.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Apr-05 19:44 scribe_data/extract_transform/German/nouns/__init__.py
 -rw-r--r--  2.0 unx     7864 b- defN 23-Apr-16 20:53 scribe_data/extract_transform/German/nouns/format_nouns.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Apr-05 19:44 scribe_data/extract_transform/German/prepositions/__init__.py
--rw-r--r--  2.0 unx     3143 b- defN 23-Apr-16 20:54 scribe_data/extract_transform/German/prepositions/format_prepositions.py
+-rw-r--r--  2.0 unx     3836 b- defN 23-Apr-22 18:06 scribe_data/extract_transform/German/prepositions/format_prepositions.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Apr-05 19:44 scribe_data/extract_transform/German/translations/__init__.py
 -rw-r--r--  2.0 unx     1393 b- defN 23-Apr-10 20:11 scribe_data/extract_transform/German/translations/format_translations.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Apr-05 19:44 scribe_data/extract_transform/German/verbs/__init__.py
 -rw-r--r--  2.0 unx     6537 b- defN 23-Apr-17 00:04 scribe_data/extract_transform/German/verbs/format_verbs.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Apr-05 19:44 scribe_data/extract_transform/Italian/__init__.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Apr-05 19:44 scribe_data/extract_transform/Italian/nouns/__init__.py
 -rw-r--r--  2.0 unx     4583 b- defN 23-Apr-16 20:54 scribe_data/extract_transform/Italian/nouns/format_nouns.py
@@ -58,18 +58,18 @@
 -rw-r--r--  2.0 unx        0 b- defN 22-Apr-05 19:44 scribe_data/extract_transform/Swedish/translations/__init__.py
 -rw-r--r--  2.0 unx     1266 b- defN 23-Apr-10 20:13 scribe_data/extract_transform/Swedish/translations/format_translations.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Apr-05 19:44 scribe_data/extract_transform/Swedish/verbs/__init__.py
 -rw-r--r--  2.0 unx     2231 b- defN 23-Apr-16 22:53 scribe_data/extract_transform/Swedish/verbs/format_verbs.py
 -rw-r--r--  2.0 unx   102823 b- defN 22-Nov-23 22:13 scribe_data/extract_transform/_resources/2021_ranked.tsv
 -rw-r--r--  2.0 unx        0 b- defN 22-Nov-23 22:13 scribe_data/extract_transform/_resources/__init__.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Apr-06 08:23 scribe_data/load/__init__.py
--rw-r--r--  2.0 unx     8655 b- defN 23-Apr-18 23:57 scribe_data/load/data_to_sqlite.py
+-rw-r--r--  2.0 unx    10012 b- defN 23-Apr-30 15:14 scribe_data/load/data_to_sqlite.py
 -rw-r--r--  2.0 unx     1185 b- defN 23-Apr-10 21:36 scribe_data/load/send_dbs_to_scribe.py
 -rw-r--r--  2.0 unx    12972 b- defN 22-Nov-04 23:06 scribe_data/load/update_data.py
 -rw-r--r--  2.0 unx     6807 b- defN 23-Apr-10 09:30 scribe_data/load/update_utils.py
--rw-r--r--  2.0 unx      420 b- defN 23-Apr-16 20:21 scribe_data-3.0.0.data/data/requirements.txt
--rw-r--r--  2.0 unx    32472 b- defN 23-Apr-19 00:33 scribe_data-3.0.0.dist-info/LICENSE.txt
--rw-r--r--  2.0 unx    15386 b- defN 23-Apr-19 00:33 scribe_data-3.0.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-19 00:33 scribe_data-3.0.0.dist-info/WHEEL
--rw-r--r--  2.0 unx       12 b- defN 23-Apr-19 00:33 scribe_data-3.0.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     7955 b- defN 23-Apr-19 00:33 scribe_data-3.0.0.dist-info/RECORD
-73 files, 322930 bytes uncompressed, 93965 bytes compressed:  70.9%
+-rw-r--r--  2.0 unx      420 b- defN 23-Apr-16 20:21 scribe_data-3.1.0.data/data/requirements.txt
+-rw-r--r--  2.0 unx    32472 b- defN 23-Apr-30 15:27 scribe_data-3.1.0.dist-info/LICENSE.txt
+-rw-r--r--  2.0 unx    15510 b- defN 23-Apr-30 15:27 scribe_data-3.1.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Apr-30 15:27 scribe_data-3.1.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       12 b- defN 23-Apr-30 15:27 scribe_data-3.1.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     7956 b- defN 23-Apr-30 15:27 scribe_data-3.1.0.dist-info/RECORD
+73 files, 325105 bytes uncompressed, 94444 bytes compressed:  70.9%
```

## zipnote {}

```diff
@@ -195,26 +195,26 @@
 
 Filename: scribe_data/load/update_data.py
 Comment: 
 
 Filename: scribe_data/load/update_utils.py
 Comment: 
 
-Filename: scribe_data-3.0.0.data/data/requirements.txt
+Filename: scribe_data-3.1.0.data/data/requirements.txt
 Comment: 
 
-Filename: scribe_data-3.0.0.dist-info/LICENSE.txt
+Filename: scribe_data-3.1.0.dist-info/LICENSE.txt
 Comment: 
 
-Filename: scribe_data-3.0.0.dist-info/METADATA
+Filename: scribe_data-3.1.0.dist-info/METADATA
 Comment: 
 
-Filename: scribe_data-3.0.0.dist-info/WHEEL
+Filename: scribe_data-3.1.0.dist-info/WHEEL
 Comment: 
 
-Filename: scribe_data-3.0.0.dist-info/top_level.txt
+Filename: scribe_data-3.1.0.dist-info/top_level.txt
 Comment: 
 
-Filename: scribe_data-3.0.0.dist-info/RECORD
+Filename: scribe_data-3.1.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## scribe_data/extract_transform/German/prepositions/format_prepositions.py

```diff
@@ -85,14 +85,42 @@
             "case" not in prep_vals.keys() and prep_vals["preposition"] != "a"
         ):  # à is the correct preposition
             prepositions_formatted[prep_vals["preposition"]] = ""
 
 for k in prepositions_formatted:
     prepositions_formatted[k] = order_annotations(prepositions_formatted[k])
 
+    # Contracted versions of German prepositions (ex: an + dem = am).
+contractedGermanPrepositions = {
+    "am": "Acc/Dat",
+    "ans": "Acc/Dat",
+    "aufs": "Acc/Dat",
+    "beim": "Dat",
+    "durchs": "Acc",
+    "fürs": "Acc",
+    "hinters": "Acc/Dat",
+    "hinterm": "Acc/Dat",
+    "ins": "Acc/Dat",
+    "im": "Acc/Dat",
+    "übers": "Acc/Dat",
+    "überm": "Acc/Dat",
+    "ums": "Acc",
+    "unters": "Acc/Dat",
+    "unterm": "Acc/Dat",
+    "vom": "Dat",
+    "vors": "Acc/Dat",
+    "vorm": "Acc/Dat",
+    "zum": "Dat",
+    "zur": "Dat",
+}
+
+for p in contractedGermanPrepositions:
+    if p not in prepositions_formatted:
+        prepositions_formatted[p] = contractedGermanPrepositions[p]
+
 prepositions_formatted = collections.OrderedDict(sorted(prepositions_formatted.items()))
 
 org_path = get_path_from_et_dir()
 export_path = "../formatted_data/prepositions.json"
 if update_data_in_use:
     export_path = f"{org_path}/Scribe-Data/src/scribe_data/extract_transform/{LANGUAGE}/formatted_data/prepositions.json"
```

## scribe_data/load/data_to_sqlite.py

```diff
@@ -102,19 +102,41 @@
 
         connection = sqlite3.connect(
             f"databases/{get_language_iso(l).upper()}LanguageData.sqlite"
         )
         cursor = connection.cursor()
 
         def create_table(word_type, cols):
+            """
+            Creates a table in the language database given a word type for its title and column names.
+
+            Parameters
+            ----------
+                word_type : str
+                    The name of the table to be created
+
+                cols : list of strings
+                    The names of columns for the new table
+            """
             cursor.execute(
                 f"CREATE TABLE IF NOT EXISTS {word_type} ({' Text, '.join(cols)} Text, UNIQUE({cols[0]}))"
             )
 
         def table_insert(word_type, keys):
+            """
+            Inserts a row into a language database table.
+
+            Parameters
+            ----------
+                word_type : str
+                    The name of the table to be inserted into
+
+                keys : list of strings
+                    The values to be inserted into the table row
+            """
             insert_question_marks = ", ".join(["?"] * len(keys))
             cursor.execute(
                 f"INSERT OR IGNORE INTO {word_type} values({insert_question_marks})",
                 keys,
             )
 
         print(f"Database for {l} {maybe_over}written and connection made.")
@@ -127,14 +149,19 @@
             if wt == "nouns":
                 cols = ["noun, plural, form"]
                 create_table(word_type=wt, cols=cols)
                 for row in json_data:
                     keys = [row, json_data[row]["plural"], json_data[row]["form"]]
                     table_insert(word_type=wt, keys=keys)
 
+                if "Scribe" not in json_data and l != "Russian":
+                    table_insert(word_type=wt, keys=["Scribe", "Scribes", ""])
+                # elif "Писец" not in json_data and l == "Russian":
+                #     table_insert(word_type=wt, keys=["Писец", "Писцы", ""])
+
                 connection.commit()
 
             elif wt == "verbs":
                 cols = ["verb"]
                 cols += json_data[list(json_data.keys())[0]].keys()
                 create_table(word_type=wt, cols=cols)
                 for row in json_data:
@@ -159,26 +186,26 @@
                 for row in json_data:
                     keys = [row, json_data[row]]
                     table_insert(word_type=wt, keys=keys)
 
                 connection.commit()
 
             elif wt == "autosuggestions":
-                cols = ["word", "suggestion_1", "suggestion_2", "suggestion_3"]
+                cols = ["word", "suggestion_0", "suggestion_1", "suggestion_2"]
                 create_table(word_type=wt, cols=cols)
                 for row in json_data:
                     keys = [row]
                     keys += [json_data[row][i] for i in range(len(json_data[row]))]
                     keys += [""] * (len(cols) - len(keys))
                     table_insert(word_type=wt, keys=keys)
 
                 connection.commit()
 
             elif wt == "emoji_keywords":
-                cols = ["word", "emoji_1", "emoji_2", "emoji_3"]
+                cols = ["word", "emoji_0", "emoji_1", "emoji_2"]
                 create_table(word_type=wt, cols=cols)
                 for row in json_data:
                     keys = [row]
                     keys += [
                         json_data[row][i]["emoji"] for i in range(len(json_data[row]))
                     ]
                     keys += [""] * (len(cols) - len(keys))
@@ -230,42 +257,54 @@
                 FROM
                 emoji_keywords
             )
 
             SELECT DISTINCT
                 -- Select an upper case noun if it's available.
                 CASE
-                WHEN
-                    UPPER(SUBSTR(lex.word, 1, 1)) || SUBSTR(lex.word, 2) = nouns_cap.noun
-                THEN
-                    nouns_cap.noun
+                    WHEN
+                        UPPER(SUBSTR(lex.word, 1, 1)) || SUBSTR(lex.word, 2) = nouns_cap.noun
+                    THEN
+                        nouns_cap.noun
+
+                    WHEN
+                        UPPER(lex.word) = nouns_upper.noun
+                    THEN
+                        nouns_upper.noun
 
-                ELSE
-                    lex.word
+                    ELSE
+                        lex.word
                 END
 
             FROM
                 full_lexicon AS lex
 
             LEFT JOIN
                 nouns AS nouns_cap
 
             ON
                 UPPER(SUBSTR(lex.word, 1, 1)) || SUBSTR(lex.word, 2) = nouns_cap.noun
 
+            LEFT JOIN
+                nouns AS nouns_upper
+
+            ON
+                UPPER(lex.word) = nouns_upper.noun
+
             WHERE
                 LENGTH(lex.word) > 1
                 AND lex.word NOT LIKE '%-%'
                 AND lex.word NOT LIKE '%/%'
                 AND lex.word NOT LIKE '%(%'
                 AND lex.word NOT LIKE '%)%'
                 AND lex.word NOT LIKE '%"%'
                 AND lex.word NOT LIKE '%“%'
                 AND lex.word NOT LIKE '%„%'
                 AND lex.word NOT LIKE '%”%'
+                AND lex.word NOT LIKE "%'%"
             """
         )
 
         connection.commit()
 
         print(f"{l} database created.")
```

## Comparing `scribe_data-3.0.0.dist-info/LICENSE.txt` & `scribe_data-3.1.0.dist-info/LICENSE.txt`

 * *Files identical despite different names*

## Comparing `scribe_data-3.0.0.dist-info/METADATA` & `scribe_data-3.1.0.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: scribe-data
-Version: 3.0.0
+Version: 3.1.0
 Summary: Wikidata and Wikipedia data extraction for Scribe applications
 Home-page: https://github.com/scribe-org/Scribe-Data
 Author: Andrew Tavis McAllister
 Author-email: andrew.t.mcallister@gmail.com
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Intended Audience :: Developers
 Classifier: Intended Audience :: Education
@@ -44,17 +44,18 @@
 [![platforms](https://img.shields.io/badge/Wikidata-990000.svg?logo=wikidata&logoColor=ffffff)](https://github.com/scribe-org/Scribe-Data)
 [![issues](https://img.shields.io/github/issues/scribe-org/Scribe-Data?label=%20&logo=github)](https://github.com/scribe-org/Scribe-Data/issues)
 [![language](https://img.shields.io/badge/Python%203-306998.svg?logo=python&logoColor=ffffff)](https://github.com/scribe-org/Scribe-Data/blob/main/CONTRIBUTING.md)
 [![pypi](https://img.shields.io/pypi/v/scribe-data.svg?label=%20&color=4B8BBE)](https://pypi.org/project/scribe-data/)
 [![pypistatus](https://img.shields.io/pypi/status/scribe-data.svg?label=%20)](https://pypi.org/project/scribe-data/)
 [![license](https://img.shields.io/github/license/scribe-org/Scribe-Data.svg?label=%20)](https://github.com/scribe-org/Scribe-Data/blob/main/LICENSE.txt)
 [![coc](https://img.shields.io/badge/Contributor%20Covenant-ff69b4.svg)](https://github.com/scribe-org/Scribe-Data/blob/main/.github/CODE_OF_CONDUCT.md)
+[![mastodon](https://img.shields.io/badge/Mastodon-6364FF.svg?logo=mastodon&logoColor=ffffff)](https://wikis.world/@scribe)
 [![twitter](https://img.shields.io/badge/Twitter-1DA1F2.svg?logo=twitter&logoColor=ffffff)](https://twitter.com/scribe_org)
-[![codestyle](https://img.shields.io/badge/black-000000.svg)](https://github.com/psf/black)
 [![matrix](https://img.shields.io/badge/Matrix-000000.svg?logo=matrix&logoColor=ffffff)](https://matrix.to/#/#scribe_community:matrix.org)
+[![codestyle](https://img.shields.io/badge/black-000000.svg)](https://github.com/psf/black)
 
 ## Wikidata and Wikipedia data extraction for Scribe applications
 
 **Scribe-Data** contains the scripts for extracting and formatting data from [Wikidata](https://www.wikidata.org/) and [Wikipedia](https://www.wikipedia.org/) for Scribe applications. Updates to the language keyboard and interface data can be done using [scribe_data/load/update_data.py](https://github.com/scribe-org/Scribe-Data/tree/main/src/scribe_data/load/update_data.py) and the notebooks within the [scribe_data/load](https://github.com/scribe-org/Scribe-Data/tree/main/src/scribe_data/load) directory.
 
 > **Note**: The [contributing](#contributing) section has information for those interested, with the articles and presentations in [featured by](#featured-by) also being good resources for learning more about Scribe.
 
@@ -112,21 +113,21 @@
 
 Scribe's goal is functional, feature-rich keyboards and interfaces for all languages. Check the [extract_transform](https://github.com/scribe-org/Scribe-Data/tree/main/src/scribe_data/extract_transform) directory for queries for currently supported languages and those that have substantial data on [Wikidata](https://www.wikidata.org/).
 
 The following table shows the supported languages and the amount of data available for each on [Wikidata](https://www.wikidata.org/) and via [Unicode CLDR](https://github.com/unicode-org/cldr) for emojis:
 
 | Languages  |   Nouns | Verbs | Translations\* | Prepositions† | Emoji Keywords |
 | :--------- | ------: | ----: | -------------: | ------------: | -------------: |
-| French     |  17,070 | 6,572 |         67,652 |             - |          2,488 |
-| German     | 102,789 | 3,592 |         67,652 |           190 |          2,898 |
-| Italian    |   8,669 |    73 |         67,652 |             - |          2,457 |
+| French     |  17,072 | 6,572 |         67,652 |             - |          2,488 |
+| German     | 102,833 | 3,593 |         67,652 |           210 |          2,898 |
+| Italian    |   8,671 |    73 |         67,652 |             - |          2,457 |
 | Portuguese |   5,437 |   536 |         67,652 |             - |          2,327 |
 | Russian    | 194,448 |    12 |         67,652 |            15 |          3,827 |
-| Spanish    |  38,755 | 4,828 |         67,652 |             - |          3,134 |
-| Swedish    |  44,624 | 4,474 |         67,652 |             - |          2,913 |
+| Spanish    |  39,105 | 4,930 |         67,652 |             - |          3,134 |
+| Swedish    |  45,259 | 4,501 |         67,652 |             - |          2,913 |
 
 `*` Given the current **`beta`** status where words are machine translated.
 
 `†` Only for languages for which preposition annotation is needed.
 
 <a id="featured-by"></a>
```

### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: scribe-data Version: 3.0.0 Summary: Wikidata and
+Metadata-Version: 2.1 Name: scribe-data Version: 3.1.0 Summary: Wikidata and
 Wikipedia data extraction for Scribe applications Home-page: https://
 github.com/scribe-org/Scribe-Data Author: Andrew Tavis McAllister Author-email:
 andrew.t.mcallister@gmail.com Classifier: Development Status :: 5 - Production/
 Stable Classifier: Intended Audience :: Developers Classifier: Intended
 Audience :: Education Classifier: License :: OSI Approved :: GNU General Public
 License v3 (GPLv3) Classifier: Programming Language :: Python Classifier:
 Programming Language :: Python :: 3 Classifier: Programming Language :: Python
@@ -29,44 +29,46 @@
 Data/blob/main/CONTRIBUTING.md) [![pypi](https://img.shields.io/pypi/v/scribe-
 data.svg?label=%20&color=4B8BBE)](https://pypi.org/project/scribe-data/) [!
 [pypistatus](https://img.shields.io/pypi/status/scribe-data.svg?label=%20)]
 (https://pypi.org/project/scribe-data/) [![license](https://img.shields.io/
 github/license/scribe-org/Scribe-Data.svg?label=%20)](https://github.com/
 scribe-org/Scribe-Data/blob/main/LICENSE.txt) [![coc](https://img.shields.io/
 badge/Contributor%20Covenant-ff69b4.svg)](https://github.com/scribe-org/Scribe-
-Data/blob/main/.github/CODE_OF_CONDUCT.md) [![twitter](https://img.shields.io/
-badge/Twitter-1DA1F2.svg?logo=twitter&logoColor=ffffff)](https://twitter.com/
-scribe_org) [![codestyle](https://img.shields.io/badge/black-000000.svg)]
-(https://github.com/psf/black) [![matrix](https://img.shields.io/badge/Matrix-
+Data/blob/main/.github/CODE_OF_CONDUCT.md) [![mastodon](https://img.shields.io/
+badge/Mastodon-6364FF.svg?logo=mastodon&logoColor=ffffff)](https://wikis.world/
+@scribe) [![twitter](https://img.shields.io/badge/Twitter-
+1DA1F2.svg?logo=twitter&logoColor=ffffff)](https://twitter.com/scribe_org) [!
+[matrix](https://img.shields.io/badge/Matrix-
 000000.svg?logo=matrix&logoColor=ffffff)](https://matrix.to/#/
-#scribe_community:matrix.org) ## Wikidata and Wikipedia data extraction for
-Scribe applications **Scribe-Data** contains the scripts for extracting and
-formatting data from [Wikidata](https://www.wikidata.org/) and [Wikipedia]
-(https://www.wikipedia.org/) for Scribe applications. Updates to the language
-keyboard and interface data can be done using [scribe_data/load/update_data.py]
+#scribe_community:matrix.org) [![codestyle](https://img.shields.io/badge/black-
+000000.svg)](https://github.com/psf/black) ## Wikidata and Wikipedia data
+extraction for Scribe applications **Scribe-Data** contains the scripts for
+extracting and formatting data from [Wikidata](https://www.wikidata.org/) and
+[Wikipedia](https://www.wikipedia.org/) for Scribe applications. Updates to the
+language keyboard and interface data can be done using [scribe_data/load/
+update_data.py](https://github.com/scribe-org/Scribe-Data/tree/main/src/
+scribe_data/load/update_data.py) and the notebooks within the [scribe_data/
+load](https://github.com/scribe-org/Scribe-Data/tree/main/src/scribe_data/load)
+directory. > **Note**: The [contributing](#contributing) section has
+information for those interested, with the articles and presentations in
+[featured by](#featured-by) also being good resources for learning more about
+Scribe. Scribe applications are available on [iOS](https://github.com/scribe-
+org/Scribe-iOS), [Android](https://github.com/scribe-org/Scribe-Android) (WIP)
+and [Desktop](https://github.com/scribe-org/Scribe-Desktop) (planned).  #
+**Contents** - [Process](#process) - [Contributing](#contributing) - [Supported
+Languages](#supported-languages) - [Featured By](#featured-by)  # Process
+[`â§`](#contents) [scribe_data/load/update_data.py](https://github.com/scribe-
+org/Scribe-Data/tree/main/src/scribe_data/load/update_data.py) and the
+notebooks within the [scribe_data/load](https://github.com/scribe-org/Scribe-
+Data/tree/main/src/scribe_data/load) directory are used to update all data for
+[Scribe-iOS](https://github.com/scribe-org/Scribe-iOS), with this functionality
+later being expanded to update [Scribe-Android](https://github.com/scribe-org/
+Scribe-Android) and [Scribe-Desktop](https://github.com/scribe-org/Scribe-
+Desktop) when they're active. The main data update process in [update_data.py]
 (https://github.com/scribe-org/Scribe-Data/tree/main/src/scribe_data/load/
-update_data.py) and the notebooks within the [scribe_data/load](https://
-github.com/scribe-org/Scribe-Data/tree/main/src/scribe_data/load) directory. >
-**Note**: The [contributing](#contributing) section has information for those
-interested, with the articles and presentations in [featured by](#featured-by)
-also being good resources for learning more about Scribe. Scribe applications
-are available on [iOS](https://github.com/scribe-org/Scribe-iOS), [Android]
-(https://github.com/scribe-org/Scribe-Android) (WIP) and [Desktop](https://
-github.com/scribe-org/Scribe-Desktop) (planned).  # **Contents** - [Process]
-(#process) - [Contributing](#contributing) - [Supported Languages](#supported-
-languages) - [Featured By](#featured-by)  # Process [`â§`](#contents)
-[scribe_data/load/update_data.py](https://github.com/scribe-org/Scribe-Data/
-tree/main/src/scribe_data/load/update_data.py) and the notebooks within the
-[scribe_data/load](https://github.com/scribe-org/Scribe-Data/tree/main/src/
-scribe_data/load) directory are used to update all data for [Scribe-iOS](https:
-//github.com/scribe-org/Scribe-iOS), with this functionality later being
-expanded to update [Scribe-Android](https://github.com/scribe-org/Scribe-
-Android) and [Scribe-Desktop](https://github.com/scribe-org/Scribe-Desktop)
-when they're active. The main data update process in [update_data.py](https://
-github.com/scribe-org/Scribe-Data/tree/main/src/scribe_data/load/
 update_data.py) triggers [SPARQL queries](https://github.com/scribe-org/Scribe-
 Data/tree/main/src/scribe_data/extract_transform) to query language data from
 [Wikidata](https://www.wikidata.org/) using [SPARQLWrapper](https://github.com/
 RDFLib/sparqlwrapper) as a URI. The autosuggestion process derives popular
 words from [Wikipedia](https://www.wikipedia.org/) as well as those words that
 normally follow them for an effective baseline feature until natural language
 processing techniques are employed. Functions to generate autosuggestions are
@@ -123,19 +125,19 @@
 scribe_data/extract_transform) directory for queries for currently supported
 languages and those that have substantial data on [Wikidata](https://
 www.wikidata.org/). The following table shows the supported languages and the
 amount of data available for each on [Wikidata](https://www.wikidata.org/) and
 via [Unicode CLDR](https://github.com/unicode-org/cldr) for emojis: | Languages
 | Nouns | Verbs | Translations\* | Prepositionsâ  | Emoji Keywords | | :------
 --- | ------: | ----: | -------------: | ------------: | -------------: | |
-French | 17,070 | 6,572 | 67,652 | - | 2,488 | | German | 102,789 | 3,592 |
-67,652 | 190 | 2,898 | | Italian | 8,669 | 73 | 67,652 | - | 2,457 | |
+French | 17,072 | 6,572 | 67,652 | - | 2,488 | | German | 102,833 | 3,593 |
+67,652 | 210 | 2,898 | | Italian | 8,671 | 73 | 67,652 | - | 2,457 | |
 Portuguese | 5,437 | 536 | 67,652 | - | 2,327 | | Russian | 194,448 | 12 |
-67,652 | 15 | 3,827 | | Spanish | 38,755 | 4,828 | 67,652 | - | 3,134 | |
-Swedish | 44,624 | 4,474 | 67,652 | - | 2,913 | `*` Given the current
+67,652 | 15 | 3,827 | | Spanish | 39,105 | 4,930 | 67,652 | - | 3,134 | |
+Swedish | 45,259 | 4,501 | 67,652 | - | 2,913 | `*` Given the current
 **`beta`** status where words are machine translated. `â ` Only for languages
 for which preposition annotation is needed.  # Featured By [`â§`](#contents)
 Articles and Presentations on Scribe
 2023 - [Presentation slides](https://docs.google.com/presentation/d/
 1W4ZkGi9UDDiTxM_silEij0gTE8YEubluHxe78xoqEP0/edit?usp=sharing) for a talk at
 [Berlin Hack and Tell](https://berlinhackandtell.rocks/) ([Hack of the month
 winner ð](https://berlinhackandtell.rocks/2023-03-28-no87-moore-hacks)) 2022
```

## Comparing `scribe_data-3.0.0.dist-info/RECORD` & `scribe_data-3.1.0.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 scribe_data/extract_transform/French/translations/format_translations.py,sha256=oft9eeNlNewZZwr6zopqY0FQ23Klf9kT93jrqvS4a2Q,1266
 scribe_data/extract_transform/French/verbs/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 scribe_data/extract_transform/French/verbs/format_verbs.py,sha256=3PjLAS6veFKE7wdOuBBkHwMfVc7YPjOiI1JrccbpKKo,2271
 scribe_data/extract_transform/German/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 scribe_data/extract_transform/German/nouns/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 scribe_data/extract_transform/German/nouns/format_nouns.py,sha256=pZRL4OBYn2C9UWuXb75N9IGKDcuWcOZbhPqXt60Y3Bs,7864
 scribe_data/extract_transform/German/prepositions/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-scribe_data/extract_transform/German/prepositions/format_prepositions.py,sha256=I3UfZ4eRWnrgoVs81jYBglQsrMtvFAnHT6ld0K1tHxw,3143
+scribe_data/extract_transform/German/prepositions/format_prepositions.py,sha256=VlI6HCZZttUF90oAcz4sN3gsl-ErKNSXlXazgo6Agkg,3836
 scribe_data/extract_transform/German/translations/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 scribe_data/extract_transform/German/translations/format_translations.py,sha256=yXvOTDKV6lKL5np6s6utmFY--HdEcZ9GL44gWXg3IOo,1393
 scribe_data/extract_transform/German/verbs/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 scribe_data/extract_transform/German/verbs/format_verbs.py,sha256=bJsvYosIqoas3n7zsmVW-EPtjtX1t_UnoiPhEDuHR3w,6537
 scribe_data/extract_transform/Italian/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 scribe_data/extract_transform/Italian/nouns/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 scribe_data/extract_transform/Italian/nouns/format_nouns.py,sha256=xjHUpeqSqGJcno1_w48gbetFkKA2vRPjWSCseYndGpE,4583
@@ -57,17 +57,17 @@
 scribe_data/extract_transform/Swedish/translations/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 scribe_data/extract_transform/Swedish/translations/format_translations.py,sha256=CLyy0JvG3bUhoONzXExPEUL8dXRdsS6xRGm5GqK3ELw,1266
 scribe_data/extract_transform/Swedish/verbs/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 scribe_data/extract_transform/Swedish/verbs/format_verbs.py,sha256=0WyNcV8e__QqiY9Mwl8ohR-64BAWJe9MsDqiHMY64gE,2231
 scribe_data/extract_transform/_resources/2021_ranked.tsv,sha256=1XXrIZetJHgCBkjmfbCLhuIbO8f4FPqBRLnQ2hH74Bc,102823
 scribe_data/extract_transform/_resources/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 scribe_data/load/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-scribe_data/load/data_to_sqlite.py,sha256=jXXgbqQgukkwpGxEo-HlnbjvtK6cbr1dSwyVhYDE33Q,8655
+scribe_data/load/data_to_sqlite.py,sha256=q84FQzGNCwTxH8DCpsIZRoMJ8yFjFqKjsGdb5JqHr3c,10012
 scribe_data/load/send_dbs_to_scribe.py,sha256=kA2gfrIEhOzW9OP5h17bzKCcHfJ5YeLqIQRO5MwZh3w,1185
 scribe_data/load/update_data.py,sha256=ouQ9WOk9sYL1kFJfQDkGos0-8jz_5th2TgYB57mtmOA,12972
 scribe_data/load/update_utils.py,sha256=x_EW8OE2t5AwcCmYk1LJ72GpLVtxydry4MVWh_u0u7c,6807
-scribe_data-3.0.0.data/data/requirements.txt,sha256=D3SMCkZqONrtoRBNpV7-5nipZmaLZXfvVGAgfr6Cmhw,420
-scribe_data-3.0.0.dist-info/LICENSE.txt,sha256=xh8S2nza1Sa9y-1HpMCmA-YNu_2vi2aTPNCI6RMsMD8,32472
-scribe_data-3.0.0.dist-info/METADATA,sha256=RA1Fqq6ky1QE-6ldU2sjCQaSQkh1__8mXaSJIp66f_Y,15386
-scribe_data-3.0.0.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
-scribe_data-3.0.0.dist-info/top_level.txt,sha256=GZ2cJsBl_mJRjLt4ZRE21TpBtIqZMjB46rmPaxur-wo,12
-scribe_data-3.0.0.dist-info/RECORD,,
+scribe_data-3.1.0.data/data/requirements.txt,sha256=D3SMCkZqONrtoRBNpV7-5nipZmaLZXfvVGAgfr6Cmhw,420
+scribe_data-3.1.0.dist-info/LICENSE.txt,sha256=xh8S2nza1Sa9y-1HpMCmA-YNu_2vi2aTPNCI6RMsMD8,32472
+scribe_data-3.1.0.dist-info/METADATA,sha256=s1AHE66qM5YKHi1s26CfNo458HroOKBv80gdUb_Dt5w,15510
+scribe_data-3.1.0.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
+scribe_data-3.1.0.dist-info/top_level.txt,sha256=GZ2cJsBl_mJRjLt4ZRE21TpBtIqZMjB46rmPaxur-wo,12
+scribe_data-3.1.0.dist-info/RECORD,,
```

